{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the necessary Libraries"
      ],
      "metadata": {
        "id": "T6jWn8QXVX6Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oVyXPY77T21_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "LeakyReLU(negative_slope=0.01)  # Use negative_slope instead of alpha\n",
        "\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import xgboost as xgb\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the Dataset\n"
      ],
      "metadata": {
        "id": "MYBVhE3gVfA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "file_path = \"/content/TASK-ML-INTERN.csv\"\n",
        "data = pd.read_csv(file_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "fiKFyoHAUN2q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Droppin the non-numeric columns\n",
        "\n",
        "#  Standardizing the data\n"
      ],
      "metadata": {
        "id": "mln6mlRDVpnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = data.drop(columns=['hsi_id'])\n",
        "\n",
        "\n",
        "scaler_X = StandardScaler()\n",
        "X_scaled = scaler_X.fit_transform(data.iloc[:, :-1])\n",
        "\n"
      ],
      "metadata": {
        "id": "XEKmxTFNUStN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Log-transforming target variable to reduce skewness"
      ],
      "metadata": {
        "id": "IA8AafN7WIk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['vomitoxin_ppb'] = np.log1p(data['vomitoxin_ppb'])\n",
        "\n"
      ],
      "metadata": {
        "id": "AED1LWBxUcGE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Selection using Lasso (increased alpha for better regularization)\n"
      ],
      "metadata": {
        "id": "XDM6YwBmWdNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lasso = Lasso(alpha=0.005, max_iter=10000)\n",
        "lasso.fit(X_scaled, data['vomitoxin_ppb'])\n",
        "selected_features = SelectFromModel(lasso, prefit=True)\n",
        "X_selected = selected_features.transform(X_scaled)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWgZMO-PUipq",
        "outputId": "7e135e4f-7426-4b46-b8b2-8b1ad99737e2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.887e+02, tolerance: 4.358e-01\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Appling PCA with dynamic variance retention\n"
      ],
      "metadata": {
        "id": "bi-8smfnWlgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=0.98)  # Retain 98% variance\n",
        "X_pca = pca.fit_transform(X_selected)\n",
        "\n"
      ],
      "metadata": {
        "id": "4-w76AGdUl_K"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split dataset"
      ],
      "metadata": {
        "id": "VR5IzaqTWqKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pca, data['vomitoxin_ppb'], test_size=0.2, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "vuFHe1_cUqWm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train an optimized XGBoost Regressor"
      ],
      "metadata": {
        "id": "crADxVTZWunM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "xgb_model = xgb.XGBRegressor(\n",
        "    objective='reg:squarederror',\n",
        "    n_estimators=2000,\n",
        "    learning_rate=0.003,\n",
        "    max_depth=10,\n",
        "    subsample=0.9,\n",
        "    colsample_bytree=0.9,\n",
        "    early_stopping_rounds=100,\n",
        "    eval_metric='rmse'\n",
        ")\n",
        "xgb_model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "aKV-YbsFUwOR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train an optimized Random Forest Regressor"
      ],
      "metadata": {
        "id": "WGkCP04dXEko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "rf_model = RandomForestRegressor(n_estimators=700, max_depth=18, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "Ke9J8_avWy6v"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to evaluate model on both training and test sets"
      ],
      "metadata": {
        "id": "EsNj0l2wXGi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def evaluate_model(model_name, y_train, y_train_pred, y_test, y_test_pred):\n",
        "    mae_train = mean_absolute_error(y_train, y_train_pred)\n",
        "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
        "    rmse_train = np.sqrt(mse_train)\n",
        "    r2_train = r2_score(y_train, y_train_pred)\n",
        "\n",
        "    mae_test = mean_absolute_error(y_test, y_test_pred)\n",
        "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
        "    rmse_test = np.sqrt(mse_test)\n",
        "    r2_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "    print(f\"--- {model_name} ---\")\n",
        "    print(f\"Train -> MAE: {mae_train:.4f}, RMSE: {rmse_train:.4f}, R²: {r2_train:.4f}\")\n",
        "    print(f\"Test  -> MAE: {mae_test:.4f}, RMSE: {rmse_test:.4f}, R²: {r2_test:.4f}\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "RZhDb3EMVMjU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train an optimized SVR"
      ],
      "metadata": {
        "id": "-x32IlrlXIvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "svr_model = SVR(kernel='rbf', C=10, gamma='scale')\n",
        "svr_model.fit(X_train, y_train)\n",
        "y_pred_svr = svr_model.predict(X_test)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "me3ryAwTW1P2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build improved neural network model"
      ],
      "metadata": {
        "id": "QQy0es_hXLex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "model = Sequential([\n",
        "    Input(shape=(X_train.shape[1],)),  # Explicit input layer\n",
        "    Dense(512, activation='swish'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    Dense(256, activation='swish'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    Dense(128, activation='swish'),\n",
        "    Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TcRo8mr9W3zT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compile model with dynamic learning rate adjustment"
      ],
      "metadata": {
        "id": "MkkDhWSbXNs6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='mse',\n",
        "    metrics=['mae']\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "3z0R8o4YW6he"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Callbacks for better training stability"
      ],
      "metadata": {
        "id": "WjD9YeF-XPq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "callbacks = [\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-5),\n",
        "    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "]"
      ],
      "metadata": {
        "id": "_OXle_piW8SC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model"
      ],
      "metadata": {
        "id": "7D33uBLvXCmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=500, batch_size=32, verbose=1, callbacks=callbacks)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred_nn = model.predict(X_test).flatten()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWUAqUm9VMs5",
        "outputId": "6bcc11e5-f1b0-4dff-8d9f-feba76c9bb95"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - loss: 24.3651 - mae: 4.3321 - val_loss: 27.7642 - val_mae: 4.8295 - learning_rate: 0.0010\n",
            "Epoch 2/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7.6697 - mae: 2.1941 - val_loss: 21.5233 - val_mae: 4.3111 - learning_rate: 0.0010\n",
            "Epoch 3/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.3175 - mae: 2.2883 - val_loss: 19.2094 - val_mae: 4.0958 - learning_rate: 0.0010\n",
            "Epoch 4/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.7579 - mae: 2.1157 - val_loss: 15.2380 - val_mae: 3.6526 - learning_rate: 0.0010\n",
            "Epoch 5/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7.1261 - mae: 2.0899 - val_loss: 13.2352 - val_mae: 3.3852 - learning_rate: 0.0010\n",
            "Epoch 6/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.8261 - mae: 2.0200 - val_loss: 12.2536 - val_mae: 3.1912 - learning_rate: 0.0010\n",
            "Epoch 7/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.7336 - mae: 2.0595 - val_loss: 11.2390 - val_mae: 3.1061 - learning_rate: 0.0010\n",
            "Epoch 8/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.7010 - mae: 2.0530 - val_loss: 12.4282 - val_mae: 3.2576 - learning_rate: 0.0010\n",
            "Epoch 9/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 6.0627 - mae: 2.0229 - val_loss: 9.7123 - val_mae: 2.8562 - learning_rate: 0.0010\n",
            "Epoch 10/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 5.4426 - mae: 1.8017 - val_loss: 9.2554 - val_mae: 2.7683 - learning_rate: 0.0010\n",
            "Epoch 11/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 5.7678 - mae: 1.8974 - val_loss: 9.6476 - val_mae: 2.7878 - learning_rate: 0.0010\n",
            "Epoch 12/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 5.2844 - mae: 1.8522 - val_loss: 8.0487 - val_mae: 2.5402 - learning_rate: 0.0010\n",
            "Epoch 13/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.7295 - mae: 1.7498 - val_loss: 8.5953 - val_mae: 2.5822 - learning_rate: 0.0010\n",
            "Epoch 14/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 4.8880 - mae: 1.7470 - val_loss: 7.8809 - val_mae: 2.4651 - learning_rate: 0.0010\n",
            "Epoch 15/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 6.2041 - mae: 1.9606 - val_loss: 7.3358 - val_mae: 2.2429 - learning_rate: 0.0010\n",
            "Epoch 16/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5.1488 - mae: 1.7683 - val_loss: 7.2576 - val_mae: 2.1789 - learning_rate: 0.0010\n",
            "Epoch 17/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.7235 - mae: 1.6927 - val_loss: 6.6555 - val_mae: 2.1103 - learning_rate: 0.0010\n",
            "Epoch 18/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.7985 - mae: 1.7564 - val_loss: 7.1447 - val_mae: 2.1608 - learning_rate: 0.0010\n",
            "Epoch 19/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 4.2042 - mae: 1.6723 - val_loss: 6.5261 - val_mae: 1.9065 - learning_rate: 0.0010\n",
            "Epoch 20/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.8567 - mae: 1.5321 - val_loss: 6.7104 - val_mae: 1.9034 - learning_rate: 0.0010\n",
            "Epoch 21/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.8350 - mae: 1.5782 - val_loss: 6.9005 - val_mae: 1.9765 - learning_rate: 0.0010\n",
            "Epoch 22/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.8112 - mae: 1.5415 - val_loss: 6.9670 - val_mae: 1.9355 - learning_rate: 0.0010\n",
            "Epoch 23/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3.8292 - mae: 1.5573 - val_loss: 6.9085 - val_mae: 1.9511 - learning_rate: 0.0010\n",
            "Epoch 24/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 3.7902 - mae: 1.5310 - val_loss: 6.6952 - val_mae: 1.9475 - learning_rate: 0.0010\n",
            "Epoch 25/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.6262 - mae: 1.5017 - val_loss: 6.7429 - val_mae: 1.9228 - learning_rate: 0.0010\n",
            "Epoch 26/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 3.6949 - mae: 1.5169 - val_loss: 6.4177 - val_mae: 1.8523 - learning_rate: 0.0010\n",
            "Epoch 27/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 3.6583 - mae: 1.5092 - val_loss: 6.6714 - val_mae: 1.8880 - learning_rate: 0.0010\n",
            "Epoch 28/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.4924 - mae: 1.4520 - val_loss: 6.8016 - val_mae: 1.9150 - learning_rate: 0.0010\n",
            "Epoch 29/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.9168 - mae: 1.3443 - val_loss: 6.7281 - val_mae: 1.8769 - learning_rate: 0.0010\n",
            "Epoch 30/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.7771 - mae: 1.2874 - val_loss: 7.1357 - val_mae: 1.9553 - learning_rate: 0.0010\n",
            "Epoch 31/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2.9575 - mae: 1.3553 - val_loss: 7.3232 - val_mae: 1.8743 - learning_rate: 0.0010\n",
            "Epoch 32/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.5305 - mae: 1.2253 - val_loss: 7.7063 - val_mae: 2.0932 - learning_rate: 0.0010\n",
            "Epoch 33/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.9734 - mae: 1.3587 - val_loss: 7.0214 - val_mae: 1.8816 - learning_rate: 0.0010\n",
            "Epoch 34/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3.0470 - mae: 1.3999 - val_loss: 7.3654 - val_mae: 2.0262 - learning_rate: 0.0010\n",
            "Epoch 35/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.4330 - mae: 1.2389 - val_loss: 7.3500 - val_mae: 1.9493 - learning_rate: 0.0010\n",
            "Epoch 36/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.6972 - mae: 1.2769 - val_loss: 7.1356 - val_mae: 1.9476 - learning_rate: 0.0010\n",
            "Epoch 37/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.5356 - mae: 1.2861 - val_loss: 7.2476 - val_mae: 1.9153 - learning_rate: 5.0000e-04\n",
            "Epoch 38/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.1518 - mae: 1.1513 - val_loss: 7.3167 - val_mae: 1.9587 - learning_rate: 5.0000e-04\n",
            "Epoch 39/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.1001 - mae: 1.1717 - val_loss: 7.5368 - val_mae: 2.0161 - learning_rate: 5.0000e-04\n",
            "Epoch 40/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.4981 - mae: 1.2046 - val_loss: 7.3225 - val_mae: 1.9196 - learning_rate: 5.0000e-04\n",
            "Epoch 41/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.7845 - mae: 1.0619 - val_loss: 7.5356 - val_mae: 1.9871 - learning_rate: 5.0000e-04\n",
            "Epoch 42/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.1324 - mae: 1.1543 - val_loss: 7.7004 - val_mae: 2.0029 - learning_rate: 5.0000e-04\n",
            "Epoch 43/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.9692 - mae: 1.0905 - val_loss: 7.4825 - val_mae: 1.9659 - learning_rate: 5.0000e-04\n",
            "Epoch 44/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.9918 - mae: 1.0703 - val_loss: 7.7360 - val_mae: 2.0199 - learning_rate: 5.0000e-04\n",
            "Epoch 45/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.0143 - mae: 1.0977 - val_loss: 7.8667 - val_mae: 2.0527 - learning_rate: 5.0000e-04\n",
            "Epoch 46/500\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.8430 - mae: 1.0617 - val_loss: 7.9778 - val_mae: 2.0488 - learning_rate: 5.0000e-04\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict on test set"
      ],
      "metadata": {
        "id": "d9M1ISTOZDrM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_pred_nn = model.predict(X_test).flatten()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdsiYnFBZB3Q",
        "outputId": "72f472e5-2035-4fe5-e202-5d128ca3886d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to evaluate model on both training and test sets\n"
      ],
      "metadata": {
        "id": "bJnu2Fc-ZFSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def evaluate_model(model_name, y_train, y_train_pred, y_test, y_test_pred):\n",
        "    mae_train = mean_absolute_error(y_train, y_train_pred)\n",
        "    mse_train = mean_squared_error(y_train, y_train_pred)\n",
        "    rmse_train = np.sqrt(mse_train)\n",
        "    r2_train = r2_score(y_train, y_train_pred)\n",
        "\n",
        "    mae_test = mean_absolute_error(y_test, y_test_pred)\n",
        "    mse_test = mean_squared_error(y_test, y_test_pred)\n",
        "    rmse_test = np.sqrt(mse_test)\n",
        "    r2_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "    print(f\"--- {model_name} ---\")\n",
        "    print(f\"Train -> MAE: {mae_train:.4f}, RMSE: {rmse_train:.4f}, R²: {r2_train:.4f}\")\n",
        "    print(f\"Test  -> MAE: {mae_test:.4f}, RMSE: {rmse_test:.4f}, R²: {r2_test:.4f}\\n\")"
      ],
      "metadata": {
        "id": "_2AX84T6Y-Qn"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictions for training set"
      ],
      "metadata": {
        "id": "x8yyVsB8XRfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_train_pred_xgb = xgb_model.predict(X_train)\n",
        "y_train_pred_rf = rf_model.predict(X_train)\n",
        "y_train_pred_svr = svr_model.predict(X_train)\n",
        "y_train_pred_nn = model.predict(X_train).flatten()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ij5DhQPfVTnz",
        "outputId": "4cea21d8-42c5-470a-ebbc-3b896a81d084"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate models on both train and test sets"
      ],
      "metadata": {
        "id": "QezVxBPnXUft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "evaluate_model(\"XGBoost\", y_train, y_train_pred_xgb, y_test, y_pred_xgb)\n",
        "evaluate_model(\"Random Forest\", y_train, y_train_pred_rf, y_test, y_pred_rf)\n",
        "evaluate_model(\"SVR\", y_train, y_train_pred_svr, y_test, y_pred_svr)\n",
        "evaluate_model(\"Neural Network\", y_train, y_train_pred_nn, y_test, y_pred_nn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_qm_ykHVTkZ",
        "outputId": "e339aa5c-c303-4493-9e09-d4dca47b249e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- XGBoost ---\n",
            "Train -> MAE: 0.7203, RMSE: 0.9549, R²: 0.8971\n",
            "Test  -> MAE: 2.0458, RMSE: 2.6420, R²: 0.1402\n",
            "\n",
            "--- Random Forest ---\n",
            "Train -> MAE: 0.7556, RMSE: 0.9572, R²: 0.8966\n",
            "Test  -> MAE: 2.0772, RMSE: 2.6427, R²: 0.1397\n",
            "\n",
            "--- SVR ---\n",
            "Train -> MAE: 1.4793, RMSE: 2.3996, R²: 0.3501\n",
            "Test  -> MAE: 1.7142, RMSE: 2.6939, R²: 0.1061\n",
            "\n",
            "--- Neural Network ---\n",
            "Train -> MAE: 1.3023, RMSE: 1.7118, R²: 0.6693\n",
            "Test  -> MAE: 1.8523, RMSE: 2.5333, R²: 0.2095\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dzuTfWKuVTh_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "noGD3oPpVQXr"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}